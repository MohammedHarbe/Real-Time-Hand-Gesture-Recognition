ğŸ– Real-Time Hand Gesture Recognition
Graduation Project â€“ AMIT AI Engineering Track
ğŸ“Œ Project Overview

This project implements a real-time hand gesture recognition system using two different AI approaches:

1ï¸âƒ£ Option A â€“ Deep Learning (YOLO Classifier)

2ï¸âƒ£ Option B â€“ Landmark-Based ML (MediaPipe + Scikit-Learn)

The system performs:

Dataset creation

Preprocessing (hand cropping)

Model training (GPU supported)

Evaluation & comparison

Real-time webcam inference

The goal is to compare deep learning vs feature-based ML in terms of:

Accuracy

Stability

Real-world performance

Inference speed

ğŸ§  System Architecture
Webcam â†’ Hand Detection â†’ Feature Extraction â†’ Model Prediction â†’ Display Result
Option A â€“ YOLO26n Classification

Model: YOLO (Ultralytics)

Input: Cropped hand images (224x224)

Training: GPU (RTX 3050 Ti)

Output: Gesture class (1â€“5)

Option B â€“ Landmark-Based Classifier

Hand detection: MediaPipe

Features: 21 landmarks Ã— (x,y,z) = 63 features

Model: Scikit-learn Pipeline (StandardScaler + Classifier)

Lightweight & CPU-friendly

ğŸ“‚ Project Structure

Hand-Gesture-AMIT
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Real_Time_Hand_Gesture_Recognition_AMIT_FIXED.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ webcam_compare.py
â”‚   â””â”€â”€ crop_hands.py
â”‚
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ optionB_best_model.joblib
â”‚
â”œâ”€â”€ .vscode/
â”‚   â”œâ”€â”€ launch.json
â”‚   â””â”€â”€ settings.json
â”‚
â””â”€â”€ README.md

âš™ï¸ Installation

1ï¸âƒ£ Create Conda Environment
conda create -n handai python=3.10 -y
conda activate handai
2ï¸âƒ£ Install Dependencies
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install ultralytics mediapipe opencv-python scikit-learn numpy matplotlib joblib
ğŸš€ Training
YOLO Training
model = YOLO("yolo26n-cls.pt")
model.train(
    data="path/to/dataset",
    epochs=50,
    imgsz=224,
    device=0
)
ğŸ¥ Run Real-Time Demo
From VS Code

Press F5

OR

python src/webcam_compare.py

Press Q to exit.

ğŸ“Š Results
Model	Validation Accuracy	Real-Time Stability
YOLO26n	~90%	High (after cropping)
Landmark ML	~88â€“95%	Very stable

Observation:

YOLO performs better numerically

Landmark model sometimes feels more stable in uncontrolled lighting

Combining both gives robust performance

ğŸ”¥ GPU Info

Device: NVIDIA RTX 3050 Ti Laptop GPU

CUDA: Enabled

Torch Version: CUDA 12.1

ğŸ§ª Key Engineering Lessons

Dataset consistency is critical (train distribution = inference distribution)

Feature mismatch (42 vs 63) causes scaler failure

GPU acceleration significantly reduces training time

Real-time preprocessing matters more than validation metrics

ğŸ‘¨â€ğŸ’» Author

Mohamed Walid
AI Engineering â€“ AMIT
Graduation Project 2026

ğŸ“œ License


Academic use only â€“ Graduation Project

